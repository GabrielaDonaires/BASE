from pyspark import SparkContext
sc = SparkContext("local", "EjemploIntersection")

data1 = [1, 2, 3, 4]
data2 = [3, 4, 5, 6]
rdd1 = sc.parallelize(data1)
rdd2 = sc.parallelize(data2)

rdd_interseccion = rdd1.intersection(rdd2)


for elemento in rdd_interseccion.collect():
    print(elemento)
