from pyspark import SparkContext
sc = SparkContext("local", "EjemploUnion")
data1 = [1, 2, 3]
data2 = [4, 5, 6]
rdd1 = sc.parallelize(data1)
rdd2 = sc.parallelize(data2)
rdd_union = rdd1.union(rdd2)
for elemento in rdd_union.collect():
    print(elemento)
